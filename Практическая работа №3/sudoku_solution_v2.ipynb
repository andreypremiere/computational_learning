{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a603552-52ed-4ca4-ba7c-d5acbb86e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import img_as_float\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3ce11e-ab73-4d0a-baa0-a1a1f7329a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_edit_image(path):\n",
    "    \"\"\"\n",
    "    Начало обработки изображения. оттенки серого -> понижение шума -> \n",
    "    адаптивная бинаризация -> выделение контуров -> расширение линий.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(path)\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(image_gray, (9, 9), 5)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 17, 1)\n",
    "    \n",
    "    edges = cv2.Canny(binary, 50, 150, 3)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    return dilated_edges, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b09c2a-7249-4ea0-826e-184c97d3ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_contours(dilated_edges, original_image):\n",
    "    \"\"\"\n",
    "    Поиск контура сетки судоку. Находит самый большой контур, выполняет аппроксимацию линий.\n",
    "    \"\"\"\n",
    "    contours, hierarchy = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "    approx = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "\n",
    "    image_copy = original_image.copy()\n",
    "    cv2.drawContours(image_copy, [approx], -1, (0, 255, 0), 1)\n",
    "    \n",
    "    cv2.imshow(\"Sudoku Grid\", image_copy)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return approx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6d136d-f041-40dc-b1f6-a9395e645f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_rect(rect, scale=1.05):\n",
    "    \"\"\"\n",
    "    Расширяет или сжимает прямоугольник, изменяя его размеры относительно центра.\n",
    "    \"\"\"\n",
    "    center_x, center_y = np.mean(rect[:, 0]), np.mean(rect[:, 1])\n",
    "    \n",
    "    expanded_rect = []\n",
    "    for x, y in rect:\n",
    "        new_x = center_x + scale * (x - center_x) \n",
    "        new_y = center_y + scale * (y - center_y)\n",
    "        expanded_rect.append([new_x, new_y])\n",
    "    return np.array(expanded_rect, dtype=\"float32\")\n",
    "\n",
    "def order_points(pts):\n",
    "    \"\"\"\n",
    "    Упорядочивает точки в заданной последовательности.\n",
    "    \"\"\"\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]  # Верхний левый\n",
    "    rect[2] = pts[np.argmax(s)]  # Нижний правый\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]  # Верхний правый\n",
    "    rect[3] = pts[np.argmax(diff)]  # Нижний левый\n",
    "\n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffaadf0-2ae2-4631-a43a-53c72787af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_image(image, approx, max_width=450):\n",
    "    \"\"\"\n",
    "    Преобразует сетку судоку в 'ровное' изображение.\n",
    "    \"\"\"\n",
    "    points = approx.reshape(4, 2)\n",
    "    rect = order_points(points)\n",
    "\n",
    "    max_height = max_width\n",
    "    \n",
    "    expanded_rect = expand_rect(rect, scale=0.98)  # 1.1 означает увеличение на 10%\n",
    "    \n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [max_width - 1, 0],\n",
    "        [max_width - 1, max_height - 1],\n",
    "        [0, max_height - 1]\n",
    "    ], dtype=\"float32\")\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(expanded_rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (max_width, max_height))\n",
    "    \n",
    "    cv2.imshow(\"Expanded Sudoku Grid\", warped)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e641d10c-f438-4f2b-bda2-9a40219bbefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cells(warped):\n",
    "    \"\"\"\n",
    "    Извлечь ячейки из сетки судоку, разделив ее на равные части 9*9.\n",
    "    \"\"\"\n",
    "    cell_height = warped.shape[0] // 9\n",
    "    cell_width = warped.shape[1] // 9\n",
    "\n",
    "    cells = []\n",
    "    for row in range(9):\n",
    "        for col in range(9):\n",
    "            x1 = col * cell_width\n",
    "            y1 = row * cell_height\n",
    "            x2 = x1 + cell_width\n",
    "            y2 = y1 + cell_height\n",
    "            cell = warped[y1:y2, x1:x2]\n",
    "            cells.append(cell)\n",
    "\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99689186-a522-430b-acbd-b0911f85a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_cell_by_percent(cell, crop_percent=0.1):\n",
    "    \"\"\"\n",
    "    Обрезает ячейку, чтобы убрать лишние объекты (линни по краям).\n",
    "    \"\"\"\n",
    "    if not (0 <= crop_percent < 0.5):\n",
    "        raise ValueError(\"crop_percent должен быть в диапазоне от 0 до 0.5\")\n",
    "    \n",
    "    height, width = cell.shape[:2]\n",
    "\n",
    "    top = int(height * crop_percent)\n",
    "    bottom = int(height * (1 - crop_percent))\n",
    "    left = int(width * crop_percent)\n",
    "    right = int(width * (1 - crop_percent))\n",
    "\n",
    "    cropped = cell[top:bottom, left:right]\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455c5f3b-7343-4a27-a3c9-ecdb9afa8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_cell(cell):\n",
    "    \"\"\"\n",
    "    Обрабатывает ячейку.\n",
    "    \"\"\"\n",
    "    warped_gray = cv2.cvtColor(crop_cell_by_percent(cell, 0.2), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blurred_part = cv2.GaussianBlur(warped_gray, (5, 5), 3)\n",
    "    \n",
    "    binary = cv2.adaptiveThreshold(blurred_part, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 7, 1.7)\n",
    "    \n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    \n",
    "    eroded = cv2.erode(binary, kernel, iterations=1)\n",
    "    \n",
    "    border_size = int(eroded.shape[0] * 0.15)\n",
    "    \n",
    "    bordered_image = cv2.copyMakeBorder(\n",
    "    eroded, \n",
    "    border_size, border_size, border_size, border_size,  # Верх, низ, лево, право\n",
    "    cv2.BORDER_CONSTANT, \n",
    "    value=0 \n",
    "    )\n",
    "    \n",
    "    return bordered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce7bff6-bd80-4205-ae30-3a0adaea2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpling_massive(massive):\n",
    "    \"\"\"\n",
    "    Преобразует активность пикселей в 0 и 1 (1 - если пиксель активен).\n",
    "    \"\"\"\n",
    "    new_massive = massive.copy()\n",
    "    for i in range(len(new_massive)):\n",
    "        for j in range(len(new_massive[i])):\n",
    "            if new_massive[i][j]:\n",
    "                new_massive[i][j] = 1\n",
    "    return new_massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3a113a-5b64-4617-9914-dc47acd10d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_list_cells(cells):\n",
    "    \"\"\"\n",
    "    Формирует список, подходящий под модель.\n",
    "    \"\"\"\n",
    "    cells_edited = []\n",
    "    for i in cells:\n",
    "        cells_edited.append(edit_cell(i))\n",
    "\n",
    "    cells_resized = []\n",
    "    for i in cells_edited:\n",
    "        cells_resized.append(cv2.resize(i, (28, 28), interpolation=cv2.INTER_AREA).reshape(-1))\n",
    "\n",
    "    simple_cells_resized = simpling_massive(cells_resized)\n",
    "    return simple_cells_resized, cells_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c7b0ab-e88a-4992-ba76-fef9db2683b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_none_figure(massive):\n",
    "    \"\"\"\n",
    "    Выявляет пустые ячейки на сетке.\n",
    "    \"\"\"\n",
    "    null_massive = []\n",
    "    for i in massive:\n",
    "        count_pixel = 0\n",
    "        for j in i:\n",
    "            if j:\n",
    "                count_pixel += 1\n",
    "        if count_pixel > 40:\n",
    "            null_massive.append(1)\n",
    "        else:\n",
    "            null_massive.append(0)\n",
    "    return null_massive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c76c2964-04b7-4fe5-aa96-b3f792dc437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(path):\n",
    "    dilated_edges, image = start_edit_image(path)\n",
    "    approx = search_contours(dilated_edges, image)\n",
    "    warped = correct_image(image, approx)\n",
    "    cells = get_cells(warped)\n",
    "    simple_cells_resized, cells_resized = prepare_list_cells(cells)\n",
    "    null_massive = detect_none_figure(cells_resized)\n",
    "\n",
    "    model = joblib.load(\"mnist_model_simple.pkl\")\n",
    "    \n",
    "    y_pred = model.predict(simple_cells_resized)\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if not null_massive[i]:\n",
    "            y_pred[i] = '0'\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9118c649-b4e7-4a4b-8342-299d038758af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '0', '1', '0', '0', '5', '0', '0', '4'],\n",
       "       ['0', '0', '0', '2', '0', '0', '0', '0', '0'],\n",
       "       ['0', '0', '8', '0', '0', '0', '0', '2', '0'],\n",
       "       ['0', '1', '0', '0', '0', '0', '0', '0', '0'],\n",
       "       ['2', '0', '2', '0', '5', '0', '0', '0', '9'],\n",
       "       ['0', '0', '0', '4', '6', '0', '1', '0', '0'],\n",
       "       ['0', '2', '0', '0', '2', '0', '4', '0', '0'],\n",
       "       ['0', '0', '0', '0', '0', '0', '7', '4', '0'],\n",
       "       ['0', '0', '1', '2', '0', '0', '0', '4', '0']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_function('./sudoku_dataset/image126.jpg').reshape(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812defa-a54d-4e47-9b75-f933c3ccdc86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6eb229-bc38-44f0-b0cd-e32556ae627e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "theory_calculating",
   "language": "python",
   "name": "theory_calculating"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
